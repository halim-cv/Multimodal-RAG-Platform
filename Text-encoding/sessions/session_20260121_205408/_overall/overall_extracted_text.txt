

--- SOURCE: Chapter 4 Models and Architectures of agents ---

1 
 
Chapter 4: Agent Models and Architectures 
 
I. Introduction 
An agent perceives the environment using its sensors and it acts on its environment using 
its effectors. So, an agent can always be seen as a function linking its perceptions to its actions. 
We obtain a typology of agents if we answer the question: why does an agent act? 
Answer: How to implement the actions efficiently according to the current situation of the 
environment or other agents.  
Multi-agent systems are generally classified into two main families: 
 cognitive systems  
 and reactive systems.  
II. Agent models 
II.1. reactive agent 
Because it reacts to external events. A reactive agent just reacts immediately to changes 
in the environment.  
 they act according to a pattern of stimuli/reaction (response) to events coming from their 
environment. 
 according to a reflection pattern by responding to signals from the environment  
II.1.1. Characteristics of a reactive agent 
 Individually, reactive agents are not "intelligent" (without anticipation, without 
planning) 
 because of their large number, these reactive agents can solve problems described as 
complex  
 No explicit representation of their environment or other agents. 
 Situated actions (ants) 
 Communication via the environment by propagating signals (the environment is 
fundamental for the coordination of actions between several agents)  
 Work on these agents is more interested in modeling a society of agents 
 areas of research: artificial life, ethology (anthill, termite nest, beehive), etc.  
2 
 
 it simply contents itself with acquiring perceptions and Reacting to them by applying 
certain pre-defined type rules (situation, action).  
 it is likened to a transition function T: this function is an unordered set of type rules:  
- If condition then action  
- which are executed in an infinite and non-deterministic loop  
- behavior driven by perceptions  
 
 
 
 
 
Example of a Reactive agent 
 
- If FD and DO Then EXIT 
- If FD and DC Then OPEN 
- If FD and DL and K Then UNLOCK 
- If FD and DL Then RANDOM-WALK  
- If FK and K Then RANDOM-WALK  
- If FK and Not K Then TAKE-KEY  
 
Example of a Reactive agent  
- A guard in a game  
- As long as I see nothing, I follow my path 
- If I see an enemy  
- If he is not threatening and if I am not hurt, I attack 
him  
- If he is threatening or if I am hurt, I sound the alarm, 
and I walk away  
 
 
3 
 
II.2. Cognitive agent  
Each cognitive agent is specialized in a domain and can communicate with other agents. 
Agents are immersed in an environment in which they interact. Their structure revolves 
around three main functions: perceive, decide and act. It has a symbolic representation 
(memory capacities) of itself, its environment and other agents and is endowed with 
reasoning capacities. Each cognitive agent has a knowledge base including:  
 various information related to their areas of expertise  
 and the management of interactions with other agents and with its environment.  
They have explicit goals and plans to accomplish their goals => intentional: Planning 
(human beings) intentional behavior (explicit goals and plans)  
- Small groups of individuals can solve problems cooperatively, that need to coordinate 
their activity, and sometimes negotiate to resolve their conflicts 
II.2.1. How a cognitive agent works 
The cognitive agent has a plan P which it executes sequentially and deterministically and 
thus has sub-functions:  
 revision of beliefs,  
 cooperation (negotiation, coordination),  
 learning.  
Example of a cognitive agent  
 GO-TO FD  
 If DO Then EXIT  
 Else If DC Then OPEN ;EXIT  
 Else If DL Then If K Then 
UNLOCK;OPEN;EXIT  
 Else GO-TO FK; TAKE KEY; GO TO FD; 
UNLOCK; OPEN; EXIT I 
I.3. Deliberative agent  
Deliberative agents are agents that perform some deliberation to choose their actions.  
Such a deliberation can be done based on the goals of the agent or on a certain utility function. It 
4 
 
can take the form of a plan that reflects the sequence of actions that the agent must perform in 
order to achieve its goal  
II.4. Hybrid agent  
 Combination between the cognitive agent and the reactive agent.  
 Each of these previous categories is appropriate for a certain type of problem.  
 Nevertheless, for the majority of problems, neither a completely reactive architecture, nor 
a completely deliberative or cognitive architecture is appropriate,  
 Agents must be able to react very quickly in certain situations (reflex behavior), while in 
others they must behave with more reasoning.  
II.4.1. Reactive Agents vs Cognitive Agent  
Cognitive Agent Reactive Agents 
Explicit representation of the environment No explicit representation 
Can take into account its past No memorization of its history 
Complex agent Function stimulus/reaction 
Small number of agents Big number of agents 
 
II.5. Purely communicating agent  
(or software agent) an IT entity that:  
 Exists in an open computing system (heterogeneous networks and systems or a collection 
of processors, software and resources that they can use and they interact with) 
 can communicate with other agents,  
 has skills (services) that it can offer to other agents,  
 has a behavior, taking into account the resources and skills at its disposal and according 
to the communications it receives.  
 Compared to the notion of agent in general, A purely communicating agent is 
distinguished:  
- it has no perception of other agents  
- it does not act in an environment (its development context is naturally that of 
computer networks).  
II.6. Purely situated agent  
 Purely situated agent: a physical entity that: 
5 
 
 is located at a position in an environment •  
 able to perceive (but in a limited way) its environment  
 has a behavior, taking into account the resources and skills at its disposal and the 
perceptions  
 compared to the notion of agent in general, A purely situated agent is distinguished:  
- communications are generally not made directly, but indirectly through 
perceptions and their actions in the environment.  
II.7. Mobile Agent  
Initially introduced in 1994 with the Telescript environment. The mobile agent paradigm 
lies at the crossroads of two research areas: multi-agent systems and code mobility with more 
particularly process migration. 
Mobile agents bring to these so-called stationary agents the ability to move on the 
different nodes of a network in order to work locally on the resources.  
 an agent capable of migrating autonomously to the different sites of a network,  
 first of all, the mobile agent code and data are hosted in computer A  
 data and code are migrated to computer B.  
 After the migration, the code is executed with the data and resources available on 
computer B.  
They can provide a practical, efficient and robust framework for implementing distributed 
applications and intelligent environments such as grid computing for several reasons:  
- the search for performance  
- ease of adaptability and development of distributed applications.  
- reduced communication costs  
- reduce vulnerability  
- asynchronous execution  
- dynamic software deployment,  
- has a behavior,  
- They can reduce 
communication costs 
 
 
6 
 
III. Agent architectures  
III.1. Agent structure  
There are several ways to design agents, but regardless of the architecture adopted, an 
agent can always be seen as a function linking its perceptions to its actions. This function is 
realized and implemented by:  
 agent program that runs on a  
 architecture which also organizes the interface with the environment (perceptions, 
actions)  
Agent = Architecture + Program (behaviour) 
 
The characteristics of an architecture are:  
 physical: a kind of processing equipment with physical sensors and effectors (ordinary 
PC, robotic car with several onboard computers, cameras, and other sensors) or virtual 
as in the case of software agents 
 the architecture disposes the available perceptions of sensors to the program, executes the 
program, and puts the actions chosen, by the latter, to the effectors.  
III.2. Agent program  
The agent program implements the desired agent function. It is invoked for each new 
percept and returns an action each time: just takes the current percept from the sensors as input 
and returns an action to the effectors. The actions taken describe the behavior of the agent. An 
agent implements a behavior based on:  
 what it can do (its skills),  
 its perceptions,  
 its representation of the world  
 and the communications it has with others or with its environment. The principal of IA is: 
- how to write programs that produce rational behavior from a small amount of 
code rather than a large number of table entries  
- The agents have the same skeleton: acquiring percepts from an environment and 
generating actions using internal data structures, updated with each new percept 
arrived.  
 
7 
 
 
 
 
 
 
 
III.2.1. Agent Program Types  
Russel and Norvig group agent programs into several types, namely:  
 TABLE-DRIVEN "Table-lookup" agent example: automated taxi  
 Simple reflex agents  
 Reflex agents based on models (with internal model of the world)  
 Goal-based agents  
 Utility-Based Full Agents  
The reflex types of agents are considered reactive agents and the latter two types are 
considered deliberative agents.  
III.3. Agent Architecture  
From a designer's point of view, the architecture of an agent describes the internal 
structure (software or hardware): how to assemble the different parts of an agent so that it 
performs the actions that are expected of it to from a set of inputs?  
In other words, the architecture of an agent is a particular methodology to specify the 
construction of agents in a set of modules. The architecture of an agent is a description of its 
internal organization: the knowledge of the agent, the operations that can be performed and the 
control flow of operations. The choice of an architecture depends on:  
 designer's decision  
 how perceptions relate to actions.  
 
 
 
 
 
 
8 
 
 
 
 
 
 
 
General structure of an agent (mono)  
 
 
 
 
 
 
General structure of an interacting agent (communication via env)  
 
 
 
 
 
 
 
General structure of an interacting agent (communication via env and direct)  
 
III.4. Types of architecture 
III.4.1. Abstract Architecture  
 S = {s1, s2, …} set of states of the environment.  
 The skills of an agent are represented by the set of actions it can perform A = {a1, a2, 
…},  
 An agent can be seen as a function: Act: S* A  
 which maps a sequence (*) of states of the environment to actions.  
III.4.1.1. Abstract Architecture (Purely Reactive Agent)  
Agents decide what to do without reference to histories:  
9 
 
 Decision making is based only on the present without any reference to the past.  
 sometimes called tropic agents because they simply respond directly to their 
environment.  
 formally, the behavior of a purely reactive agent can be represented by the function: 
action: S  A  
 The abstract model must be refined (break down into subsystems)  
 The first functional decomposition of an agent is made between perception and its 
decision process on actions  
 Let P be the set of perceptions and “capture” the 
function which makes the states of the environment 
correspond to the perceptions  
 capture: S  P  
 Act: P*  A  
 2 states s1 and s2 are equivalent for the agent if it 
perceives them in a unique way: s1∈ S and s2 ∈ S and capture(s1)=capture(s2).  
III.4.1.2. Abstract Architecture (Agent with state)  
To use its past, an agent can keep its history. Let “I” be the set of internal states of the agent, 
the decision process is expressed from I, to act: I A  
 This memorization process requires the 
accumulation of knowledge by the function: 
Compile (deliberate): I * P  I 
 therefore, the agents operate according to the new 
cycle: capture - compile - act.  
 The agent perceives the world through capture, 
updates its state through compile, then chooses an 
action to perform through act,  
III.4.2. Concrete architecture  
III.4.2.1. BDI architectures  
A BDI architecture is central to the BDI theory of rational action, first proposed by 
Michael Bratman. The agent decides on the actions to be taken from its internal states which are 
expressed in the form of:  
10 
 
 Belief: knowledge of the world; the information that the agent has about the environment 
and about other agents, through its ability to perceive or through interaction with other 
agents, which is used to calculate the values of the desires (criteria). 
 Desire: goals of the agent, represent the states of the environment, which the agent would 
like to see realized. are formalized as a set of criteria that will be used to evaluate plans to 
enable the agent to achieve its goals.  
 Intention: are the desires that the agent has decided to accomplish or the actions that it 
has decided to do to accomplish its desires corresponds to the chosen instantiated plan 
The "classic" agent systems that have implemented the BDI architecture are: IRMA = 
Intelligent Resource-bounded Machine Architecture, and PRS = Procedural Reasoning 
System  
 the control cycle of a BDI agent:  
 
 
 
Example: How farmers improve cropping system using BDI agent-based architecture?  
 Proposed solution: This model includes two types of entities:  
 agricultural agents: has the following state variables: Plots, plans, intention, desires, 
beliefs (memory-last-productions, weather-last-days, price-crop, cost-crop), water, 
finance.  
 the base of desires (4 desires (criteria)): Maximize profit, Minimize financial risks, 
Minimize workload, Maximize similarities with the last chosen plan  
 The following belief base (attributes): memory-last-productions, weather-last-days, 
crop-price, crop-cost, water.  
 intention: current cropping plan.  
11 
 
 parcel agents  
III.4.2.2. Layered architectures 
 Typically, at least 2 layers, one for reactive behavior and one for proactive behavior,  
 Ability to design multiple layers  
 Topology: information and flow control between several layers  
 two types of architectures: horizontal and vertical.  
III.4.2.2.a. Horizontal layered architectures  
 In this architecture, the software layers are linked to sensor inputs and action outputs.  
 Each layer behaves like an agent and produces proposals on the type of action to be 
performed independence and conceptual simplicity.  
 for "n" different types of behavior, then we implement "n" different layers.  
 competition between layers to suggest actions  
inconsistency problem of the global behavior of the 
agent.  
 need for layer mediation: making decisions about 
which layer will have control over the agent at any 
time.  
III.4.2.2.b. Vertical layered architectures  
 In this architecture, sensor inputs and action outputs are supported by at most one layer.  
 There are one-pass and two-pass vertical architectures.  
 One pass: in this architectural model, the information arrives from the sensors on 
a specialized layer, then passes through other layers in sequence until the last one 
which drives the output (action to be taken).  
 Two passes: in the two-pass architecture, the same layer provides the agent's 
input and output interface. The information follows the same path as in the 
previous mode, then descends the architecture in the opposite direction to return 
to the single front-end layer (interface) of the agent.  
 
 
 
 
 
12 
 
 
 
 
 
 
 
 
 
Example of a layered architecture  
 development of intelligent electronic messaging (E-mail) by exploiting the agent 
paradigm to model such a system (PhD competition).  
 the use of the agent paradigm for modeling this system because the system has 
autonomous components that act in parallel A global layer architecture of the system An 
architecture for the agents of the system 
 
 
 
 
 
 
Example of a layered architecture  
 development of an intelligent tutor (computer-assisted intelligent teaching system) using 
a multi-agent approach.  
 The problem to be solved is that of teaching the main database concepts where the 
different types of knowledge come from three sources: the pedagogical expert, the expert 
in the field to be taught and the student.  
 complex pbm, distribution and heterogeneity of different types of knowledge on a set of 
communicating agents  
 the E.I.A.O system (intelligent tutors) is organized around three modules:  
- the domain (problem solving or expertise module)  
- the student model  
13 
 
-  and the pedagogical expert (tutorial model) 
                     
Agent pédagogue 
 


--- SOURCE: Chapter-2-Basic-principles-of-multi-agent-systems ---

1 
 
Course 2: Basic principles: Multi-Agent Systems (MAS) 
 
 
I. Introduction 
An agent perceives the environment using its sensors and it acts on its environment using 
its effectors. So, an agent can always be seen as a function linking its perceptions to its actions. 
We obtain a typology of agents if we answer the question: why does an agent act?  
Answer: how to implement the actions efficiently according to the current situation of the 
environment or other agents. Multi-agent systems are generally classified into two main families: 
 cognitive systems  
 and reactive systems. We try to understand: 
 Why agents are an important new approach to designing and implementing some 
software applications  
 What are agents and what are the links with other software paradigms, in particular, 
expert systems and object-oriented programming?  
II. Agents  
II.1. Definition of an agent  
In the literature, there are a multitude of definitions of agents. They differ depending on 
the type of application for which the agent is designed.  
According to J.Ferber, An Agent can be defined as: 
 an autonomous entity (real or abstract)  
 able to act on itself and its environment  
 having a partial representation of this environment  
 able to communicate with other agents (in a multi-agent universe)  
 whose behavior is the consequence of his observations, knowledge and interactions with 
other agents.  
According to Russell and Norvig, an Agent can be defined as any entity: 
 having the ability to perceive its environment through its "sensors" (sensory inputs)  
 and to act on such an environment via its “actuators”.  
 
 
 
 
2 
 
 
 Human agent “Human agents”: (eyes as sensors, hands as actuators)  
 Robotic agents: (cameras as sensors, wheels as actuators)  
 Software agent “Software agents”: (a graphical user interface as sensor and as actuator) 
II.2. Intelligent Agent 
According to Sycara and Wooldridge: An Intelligent Agent:  
 is a computer system located in an environment  
 and it acts autonomously and flexibly  
 to achieve the purposes for which it was designed,  
Flexibility?  
 Reactive: ability to perceive the environment and respond in time (develop a response 
within the required time) to changes that may affect the environment;  
 Pro-active: goal-oriented behavior by taking initiatives at the “right” time;  
 Social (Social Aptitude): ability to interact with other agents in a cooperative or 
competitive way to achieve its objectives.  
II.3. Multidimensional characteristics 
Some properties emerge from these definitions:  
 Nature: physical or virtual agents,  
 Situated: the agent is able to act on its environment from the sensory inputs it receives 
from this same environment (process control systems, embedded systems, etc.).  
 Autonomy: the agent is able to act without the intervention of a third party (human or 
agent) and controls its own actions as well as its internal state (resources);  
 Perception: of the environment by the agent.  
 Communication: the agent has the ability to communicate with other agents as well as 
with human users.  
 Reasoning: the agent can be linked to more or less complex reasoning mechanisms 
(equipped with inferential rules).  
 The environment: this is the space in which the agent will act; this can be reduced to the 
network constituted by all the agents.  
 The representational capacity: the agent can have a very local vision of its 
environment, but it can also have a broader representation of this environment and in 
particular of the agents which surround it (acquaintances).  
 Intentionality: an intentional agent is an agent guided by its goals. An intention therefore 
expresses the will of an agent to achieve a goal or perform an action.  
3 
 
 Rationality: rational agents have criteria for evaluating their actions, and select 
according to these criteria the best actions to achieve the goal. 
  Adaptability: an adaptable agent is an agent capable of controlling its aptitudes 
(communicational, behavioral, etc.) according to the environment  
 Commitment: The notion of commitment is one of the essential qualities of cooperative 
agents. A cooperative agent plans its actions by coordinating and negotiating with other 
agents. By constructing a plan to achieve a goal, the agent gives himself the means to 
achieve it and therefore undertakes to perform the actions that satisfy this goal; the agent 
believes that he has elaborated, which leads him to act accordingly.  
 Learning: an agent can memorize its experiences and adapt its behavior accordingly. 
 Mobility: an agent can move from one machine to another and possibly duplicate itself. 
 
 
 
 
 
 
 
 
II.3.1. Agent properties (autonomy)  
The objective of autonomy is robustness. Agents have control over their own internal 
states and behaviors. Behavioral autonomy is:  
 Make decisions “by yourself”  
 Have the power to say no!  
 Do not depend on others (at least for decisions) But also relates to resources:  
 To act, the agent needs a certain number of resources: energy, CPU, quantity of memory, 
access to certain sources of information,  
 while being able to manage these resources himself, 
II.4. Comparison with other technologies (objects) 
  The agent paradigm is distinguished from conventional systems such as object-oriented 
systems and expert systems. 
Object:  informatic entities that:  
 Encapsulates some state (property)  
 Communicate by sending a message  
4 
 
 capable of performing actions or methods on this state  
 Difference: an agent, like an object, encapsules a state and a behavior, BUT ? ? ?  
Object vs. Agent: Degree of Autonomy  
 An object has autonomy over its own internal state: it has control over this state, 
Example: In JAVA, you can declare private variables (or methods): accessible only 
from inside the object. They can also be declared as Public: accessible from 
anywhere,  
 But an object has no control over its own behavior: its methods are executed without 
restriction when invoked.  
 The agent has the power to negotiate or refuse requests for services (request for 
execution of actions)  
 So: In the object-oriented case, the decision depends on the object that invokes the 
method. in the agent-oriented case, the decision depends on the agent receiving the 
request  
Object vs Agent: Flexibility: flexibility is absent for objects.  
Object vs Agent: Control Flow:  
 an agent is assumed to have its own control path.  
 exercises this control in different ways (reactive, goal-directed, social)  
 has its own execution thread (thread), so an MAS has several control flows (multi-
thread)  
 object system has only one control flow  
An object is reactive: If nobody asks for the value of an attribute or activates a method of the 
object, then nothing happens, so An object is a passive (or reactive) entity.  
An agent is Proactive: An agent has internal processes that work even in the absence of external 
solicitations. An agent can therefore act even if no one asks him for anything.  
The concept of active objects makes it possible to make agents but not to make them 
intelligent (flexible and autonomous). So object-oriented languages can help build agents...  
 
 
 
 
 
5 
 
II.5. Comparison with other technologies (expert systems)  
Expert systems: is software capable of answering questions, by performing reasoning based on 
known facts and rules. It can be used in particular as a decision-making tool. An expert system 
consists of three parts:  
1. A base of facts; 
2. A rule base;  
3. An inference engine.  
Agent vs expert systems:  
 does not act on any environment, provides guidance  
 reasons, but does not act in perception of..., nor in action on...  
 does not obtain information through sensors, but through a user acting as an intermediary.  
 not autonomous: require interventions and instructions.  
 Not pro-active, adaptive, distributed.  
 ES is not supposed to cooperate with other agents (except some real-time SE like 
ARCHON) 
 The evolution of ES towards multi-expert systems was at the origin of MAS. 
III. Multi-agent systems (MAS) 
A multi-agent system is a system that consists of several organized agents, which interact or 
communicate with each other in a common environment to achieve a global objective. In SMAs: 
 the agents are (among other things) autonomous, possibly pre-existing and generally 
heterogeneous.  
 To interact, they must have the ability to: cooperate, compete or coexist, coordinate, 
negotiate among themselves.  
III.1. The elements of an SMA  
Ferber offers a general description of the structure of a Multi-Agent system: 
1. an environment: ie a space generally having a metric.  
2. a set of located objects, ie it is possible to associate each object, at a given time, with a 
position in the environment.  
3. a set of agents representing active entities of the system.  
4. a set of relations which unite objects (therefore agents) with each other.  
5. a set of operations allowing agents to perceive, produce, consume, transform, 
manipulate objects.  
6. operators responsible for representing the application of these operations and the relation 
of the world to this attempt of modification  
6 
 
 
 
 
 
 
 
 
III.2. Characteristics of an SMA  
An SMA is usually characterized by:  
 Each agent has limited information or problem-solving capabilities (abilities), 
 Thus, each agent has a partial point of view,  
 The calculation is asynchronous.  
 It is made up of one or more organizations that structure the rules of cohabitation and 
collective work between agents.  
 In the same system, an agent can belong to several organizations.  
 Total distribution of knowledge (data is decentralized) and control (no global control of 
the multi-agent system). 
III.3. Advantages and objectives  
MAS are ideal systems for representing problems with multiple solving methods. The S.M.A 
approach is justified by the properties:  
 Modularity and extensibility.  
 Speed, with parallelism.  
 Reliability and fault tolerance due to redundancy and distribution of control with shared 
responsibilities.  
 Symbolic processing at the knowledge level.  
 Reusability and portability.  
 The intervention of sophisticated interaction schemes (cooperation, coordination, 
negotiation). 
The two major research objectives in the field of S.M.A are:  
 theoretical and experimental analysis of the mechanisms.  
 The resolution of distributed programs.  
To solve two kinds of problem:  
1. Model, explain and simulate natural phenomena.  
2. The realization of complex computer systems. 
7 
 
III.4. Challenges and Constraints 
Although MASs offer many potential benefits, they also face many challenges: 
 How to formulate, describe, break down, and allocate the problems and synthesize the 
results? 
 How to enable agents to communicate and interact? What and when to communicate?  
 How to ensure that the agents act in a coherent way: by taking their decisions or actions, 
by managing the nonlocal effects of their local decisions or by avoiding harmful 
interactions? 
 How to allow agents to represent and reason about the actions, plans and knowledge of 
other agents in order to coordinate with them?  
 How to reason about the state of their coordinated processes (such as initialization or 
termination)?  
 How to recognize and reconcile disparate points of view and conflicting intentions in a 
set of agents trying to coordinate their actions?  
 How to find the best compromise between local processing at the level of a single agent 
and distributed processing between several agents (distributed processing which induces 
communication)? More generally, how to manage the distribution of limited resources?  
 How to avoid or reduce harmful behavior of the global system, such as chaotic or 
oscillatory behavior?  
 How to design technological platforms and development methodologies for MAS?  
III.5. Application fields 
3 main families of problems  
III.5.1. Simulation:  
 Studies of complex phenomena of the real 
world: ethology (social animals), sociology, 
economy, environment,  
 Represent and simulate social or natural 
systems involving a large number of 
individuals, simulation of complex systems:  
 Ecosystem with fishermen + schools of fish + 
pollutants 
 Rats and the pool 
 Insect societies: nest building and foraging in 
ants, social spiders, termites, bees,…etc. 
8 
 
 Formation of a traffic jam, opinion dynamics.  
 Collective robotics: Several robots cooperating to accomplish a mission 
Understanding of interactions between humans: behavioral simulations - explanation of the 
impact of individual behavior on the global level: 
 Customer study  
 Integration of mentally ill people  
 Model virtual environments: (massively) 
multiplayer video games (character 
intelligence), cinema (Massive software) 
(Used for the creation of film special 
effects (crowd effects)) 
 Training on environments for collective activities  
III.5.2. Collective problem solving: 
 distributed process control without centralization:  
 supervision of a production workshop: several machines, several parts, several machining 
operations, . . . organization ?  
 Automatic reorganization in the event of a breakdown.  
 supervision (Monitoring) of telecommunications networks (detection, intervention, 
repair): monitoring agents, fault diagnosis agents, transport network maintenance 
operator agent (energy, . . . ). . . etc  
III.5.3. Integration and make software interoperate with human beings and mechanical 
systems: 
 Commerce: B2C, B2B applications, purchasing processes with sophisticated negotiations 
(automated auctions, bilateral negotiation, of contracts: buyer or seller agent who 
represents the buyer, seller with different types of behavior) 
 Research and filtering of information on the Web: aggregation of services (ex: travel 
organization: train ticket, hotel room, museum ticket, etc.),  
 Diffuse computing or ambient intelligence, pervasive computing: move towards an open 
computing world, sensors in the environment (smart clothes, ad hoc networks, etc.)  
IV. Environment  
Rational agent:  
For each possible percept sequence, a rational agent should select an action that should 
maximize its performance measure, taking into account the knowledge of the agent. The 
9 
 
rationality of the agent can then be evaluated by a performance measure taking into account the 
following aspects:  
 The performance measure to define the success of the agent.  
 agent's prior knowledge of the environment.  
 The actions that the agent can perform.  
 The agent's percept sequence in time.  
Example: The vacuum cleaner world  
Perceived: location and content, e.g., [A,Dirty]  
Actions: Left, Right, Suck, NoOp  
Performance Metric: An Objective Criterion of Success for Agent Behavior  
 volume of dirt picked up,  
 time taken,  
 electricity consumed,  
 noise produced, etc.  
IV.1. Perception 
The agents can observe different things from the environment surrounded by their sensors  
 the observed data differs spatially (appearing in different places), temporally (arriving at 
different times), or semantically (requiring different interpretations),  
 makes the world partially observable to each agent  
Another problem is sensor fusion: 
 how agents can optimally combine their perceptions in order to increase their collective 
knowledge about the current state 
 In the case of simulation: a sensor is an interface between the environment and the 
agent.  
 In the case of problem solving: perception is a mechanism for selecting a point of view 
on the problem.  
 In the case of integration and collaborative systems: perception is an interpretation of 
external information. 
IV.2. Environment  
The environment is seen as a problem in which agents act as solvers. This constitutes an 
essential part (element) of situated multi-agent systems. The environment can be seen as being in 
a state “e” among a set of states E=e1, .., e,  
 The environment can change its state either spontaneously or as a result of the agent's 
actions. 
10 
 
 It is possible to represent it in two ways:  
 considering it as a monolithic block: centralized environment  
 by modeling it as a set of cells brought together in a network (cellular automaton): 
distributed environment. 
 
 
 
 
 
 
 
 
Environment of the MAS: common space to the agents of the system.  
 This environment is equipped with a set of located objects (determining the position of an 
object), passive (these objects can be perceived, destroyed, modified by agents) or active.  
 plays an important role in the behavior of an agent:  
 memory in which different traces are left,  
 source of feedback to the agent,  
Agent environment: environment of the MAS and the other agents belonging to the system.  
IV.3. Properties 
Russell and Norvig propose some properties of an environment:  
IV.3.1. Accessible vs Inaccessible: Completely Observable, Partially Observable 
Can the agent obtain complete and precise information about the environment? 
 Completely observed environment 
- if the sensors of an agent give it access to the entirety of the environment’s state 
at any moment. 
- if the sensors detect all the aspects that are relevant for the choice of action. 
- Relevance: The quality of an agent’s decision depends on the quality of the 
available information. 
- Poor information ⇒ poor decision by the agent. 
- If the agent has no sensors at all, then the environment is unobservable. 
Examples 
 The game of chess is completely observable: one can see the position of all the 
pieces. 
11 
 
 The game of poker is partially observable: one does not know the cards in the 
opponent’s hand. 
 Accessible task environment is one in which the agent can obtain complete, precise, and 
up-to-date information about the state of the environment. 
 Most moderately complex environments (for example, the Internet) are inaccessible. 
 If the environment is not completely accessible, the agent will need internal states. 
 
IV.3.2. Deterministic / Non Deterministic (stochastic)  
Is each action guaranteed to produce a unique effect? 
 
 
 
 
 
 
 
IV.3.3. Regular / Non-Regular: (episodic/ sequential):  
Does the next action of an agent depend only on the current state of the environment (episodic), 
or on an evaluation of past states of the environment (sequential)? 
 In an episodic task environment, the sequence (perceptions/actions) of the agent 
consisting of atomic episodes 
 Each episode consists of observing the environment (receives a percept) and performing 
a single action 
 this action has no influence on the environment in the next episode 
 the next episode does not depend on the actions performed during the previous episodes 
Examples:  
- Character recognition is episodic: the system's prediction does not influence the next 
character to be recognized 
- Poker Game: Deciding whether I bet or not has an impact on the next state of the game  
IV.3.4. Static / Dynamic  
 dynamic environment: the environment can change while an agent is thinking; 
otherwise, it is static. 
 Environment is semi-dynamic: with the passage of time; the environment itself does not 
change but the performance score will change. 
12 
 
 Static environments: the agent does not need to observe the world while it chooses an 
action, nor the time that passes.  
Example:  
- Crossword puzzles are static. 
- When using a stopwatch, the game of chess is semi-dynamic.  
- Driving a taxi is clearly dynamic: other vehicles and the taxi itself continue to move 
forward,  
IV.3.5. Discrete / Continuous:  
 If there is a fixed and finite number of perceptions (sensory data) and actions, the 
environment is discrete.  
Example: the game of chess is a discrete environment  
 
 
 
 
 
 
 
 
 
 
 
 
IV.4. PEAS description:  
The first step when designing a rational agent is to specify the task environment by the 
following four elements (PEAS):  
- Performance: Performance measurement  
- Environment 
- Actuators 
- Sensors 
 
 
 
 
 
13 
 
 
Example: Agent: robot for storing parts 
- Performance measure: Percentage of parts put in 
correct boxes 
- Environment: Parts conveyor, boxes 
- Actuators: mechanical arm  
- Sensors: Camera, angle sensors 
 
 
 
 
 
 
 
